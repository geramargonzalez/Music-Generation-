{"cells":[{"cell_type":"markdown","metadata":{"id":"uoJsVjtCMunI"},"source":["<table align=\"center\">\n","  <td align=\"center\"><a target=\"_blank\" href=\"http://introtodeeplearning.com\">\n","        <img src=\"https://i.ibb.co/Jr88sn2/mit.png\" style=\"padding-bottom:5px;\" />\n","      Visit MIT Deep Learning</a></td>\n","  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/MITDeepLearning/introtodeeplearning/blob/master/lab1/PT_Part2_Music_Generation.ipynb\">\n","        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n","  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/MITDeepLearning/introtodeeplearning/blob/master/lab1/PT_Part2_Music_Generation.ipynb\">\n","        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n","</table>\n","\n","# Copyright Information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUik05YqMyCH"},"outputs":[],"source":["# Copyright 2026 MIT Introduction to Deep Learning. All Rights Reserved.\n","#\n","# Licensed under the MIT License. You may not use this file except in compliance\n","# with the License. Use and/or modification of this code outside of MIT Introduction\n","# to Deep Learning must reference:\n","#\n","# © MIT Introduction to Deep Learning\n","# http://introtodeeplearning.com\n","#"]},{"cell_type":"markdown","metadata":{"id":"O-97SDET3JG-"},"source":["# Lab 1: Intro to PyTorch and Music Generation with RNNs\n","\n","# Part 2: Music Generation with RNNs\n","\n","In this portion of the lab, we will explore building a Recurrent Neural Network (RNN) for music generation using PyTorch. We will train a model to learn the patterns in raw sheet music in [ABC notation](https://en.wikipedia.org/wiki/ABC_notation) and then use this model to generate new music."]},{"cell_type":"markdown","metadata":{"id":"rsvlBQYCrE4I"},"source":["## 2.1 Dependencies\n","First, let's download the course repository, install dependencies, and import the relevant packages we'll need for this lab.\n","\n","We will be using [Comet ML](https://www.comet.com/docs/v2/) to track our model development and training runs. First, sign up for a Comet account [at this link](https://www.comet.com/signup?utm_source=mit_dl&utm_medium=partner&utm_content=github\n",") (you can use your Google or Github account). You will need to generate a new personal API Key, which you can find either in the first 'Get Started with Comet' page, under your account settings, or by pressing the '?' in the top right corner and then 'Quickstart Guide'. Enter this API key as the global variable `COMET_API_KEY`."]},{"cell_type":"markdown","metadata":{"id":"_ajvp0No4qDm"},"source":["## 2.2 Dataset\n","This cell sets up the environment for the music-generation notebook:\n"," - Installs and configures Comet ML for experiment tracking (loss curves, artifacts like audio files)\n"," - Imports PyTorch for building/training the RNN/LSTM model\n"," - Installs and imports the MIT Deep Learning helper package (mitdeeplearning)\n"," - Imports common utilities (numpy, tqdm, wav writing, etc.)\n","- Installs system tools needed to convert ABC notation into playable audio (abcmidi + timidity)\n","#\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"riVZCVK65QTH"},"outputs":[],"source":["!pip install comet_ml > /dev/null 2>&1   # Install Comet ML (silencing output)\n","import comet_ml                           # Used later to log metrics/artifacts (e.g., generated .wav files)\n","\n","# Comet ML API key: identifies your account/project.\n","# Better practice: store it in an environment variable (e.g., os.environ[\"COMET_API_KEY\"])\n","import os\n","os.environ[\"COMET_API_KEY\"] = \"iBEQDkf7eJiOAx60y9XezTeF2\"\n","COMET_API_KEY = os.environ[\"COMET_API_KEY\"]\n","\n","# --- Core ML libraries ---\n","import torch                              # Main PyTorch package\n","import torch.nn as nn                     # Neural network layers (Embedding, LSTM, Linear, etc.)\n","import torch.optim as optim               # Optimizers (Adam, SGD, etc.)\n","\n","# --- MIT helper package for this lab ---\n","!pip install mitdeeplearning --quiet      # Installs the lab utilities (dataset loading, audio helpers, etc.)\n","import mitdeeplearning as mdl             # Provides mdl.lab1.load_training_data(), play_song(), etc.\n","\n","# --- General utilities ---\n","import numpy as np                        # Numeric arrays (vectorizing characters, etc.)\n","import time                               # Timing training loops\n","import functools                          # Used sometimes for partial functions / wrappers\n","from IPython import display as ipythondisplay  # Display audio/widgets in notebooks\n","from tqdm import tqdm                     # Progress bar for training loops\n","from scipy.io.wavfile import write        # Save generated audio to .wav files\n","\n","# --- System dependencies for audio synthesis ---\n","!apt-get install abcmidi timidity > /dev/null 2>&1\n","# abcmidi: converts ABC notation -> MIDI\n","# timidity: converts MIDI -> audio you can play/save\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1770387114029,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"P7dFnP5q3Jve","outputId":"672d176c-4c83-4809-b8e3-115bcd943394"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 817 songs in text\n","\n","Example song: \n","X:1\n","T:Alexander's\n","Z: id:dc-hornpipe-1\n","M:C|\n","L:1/8\n","K:D Major\n","(3ABc|dAFA DFAd|fdcd FAdf|gfge fefd|(3efe (3dcB A2 (3ABc|!\n","dAFA DFAd|fdcd FAdf|gfge fefd|(3efe dc d2:|!\n","AG|FAdA FAdA|GBdB GBdB|Acec Acec|dfaf gecA|!\n","FAdA FAdA|GBdB GBdB|Aceg fefd|(3efe dc d2:|!\n"]}],"source":["# Download the dataset\n","songs = mdl.lab1.load_training_data()\n","\n","# Print one of the songs to inspect it in greater detail!\n","example_song = songs[0]\n","print(\"\\nExample song: \")\n","print(example_song)"]},{"cell_type":"markdown","metadata":{"id":"hKF3EHJlCAj2"},"source":["We can easily convert a song in ABC notation to an audio waveform and play it back. Be patient for this conversion to run, it can take some time."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75,"output_embedded_package_id":"1T1AZdLWFTWWxHwjG6SZwSbzxejHakmRu"},"executionInfo":{"elapsed":4740,"status":"ok","timestamp":1770387118770,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"11toYzhEEKDz","outputId":"9aa0bb9c-8f8f-4b20-e969-4a231c03874d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Convert the ABC notation to audio file and listen to it\n","mdl.lab1.play_song(example_song)"]},{"cell_type":"markdown","metadata":{"id":"7vH24yyquwKQ"},"source":["### This cell prepares the raw text dataset for a character-level model:\n"," - It concatenates all songs into one long text string (with separators)\n"," - It builds the \"vocabulary\": the set of unique characters the model can see and predict\n"," The vocabulary size defines how many classes the model must predict at each time step."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1770387118882,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"IlCgQBRVymwR","outputId":"26ae241b-1a04-4e59-d476-9c0f471c9d03"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 83 unique characters in the dataset\n"]}],"source":["# Join our list of song strings into a single string containing all songs\n","songs_joined = \"\\n\\n\".join(songs)\n","\n","# Find all unique characters in the joined string\n","vocab = sorted(set(songs_joined))\n","\n","\n","print(\"There are\", len(vocab), \"unique characters in the dataset\")"]},{"cell_type":"markdown","metadata":{"id":"rNnrKn_lL-IJ"},"source":["## 2.3 Process the dataset for the learning task\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LFjSVAlWzf-N"},"source":["### Vectorize the text\n"," This cell creates the \"tokenizer\" for a character-level model:\n"," - char2idx maps each character to an integer ID (used as model input)\n"," - idx2char maps integer IDs back to characters (used to decode generated output)\n"," These two mappings are essential for converting between human-readable text and\n"," the numeric format required by neural networks.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IalZLbvOzf-F"},"outputs":[],"source":["### Define numerical representation of text ###\n","\n","# Create a mapping from character to unique index.\n","char2idx = {u: i for i, u in enumerate(vocab)}\n","\n","# Create a mapping from indices to characters. This is\n","idx2char = np.array(vocab)"]},{"cell_type":"markdown","metadata":{"id":"tZfqhkYCymwX"},"source":["This gives us an integer representation for each character. Observe that the unique characters (i.e., our vocabulary) in the text are mapped as indices from 0 to `len(unique)`. Let's take a peek at this numerical representation of our dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1770387118911,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"FYyNlCNXymwY","outputId":"6a0aeffc-4dc8-426f-88e5-a88a2e562a6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  '\\n':   0,\n","  ' ' :   1,\n","  '!' :   2,\n","  '\"' :   3,\n","  '#' :   4,\n","  \"'\" :   5,\n","  '(' :   6,\n","  ')' :   7,\n","  ',' :   8,\n","  '-' :   9,\n","  '.' :  10,\n","  '/' :  11,\n","  '0' :  12,\n","  '1' :  13,\n","  '2' :  14,\n","  '3' :  15,\n","  '4' :  16,\n","  '5' :  17,\n","  '6' :  18,\n","  '7' :  19,\n","  ...\n","}\n"]}],"source":["print('{')\n","for char, _ in zip(char2idx, range(20)):\n","    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n","print('  ...\\n}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g-LnKyu4dczc"},"outputs":[],"source":["### Vectorize the songs string ###\n","def vectorize_string(string):\n","  return np.array([char2idx[s] for s in string])\n","\n","vectorized_songs = vectorize_string(songs_joined)\n"]},{"cell_type":"markdown","metadata":{"id":"IqxpSuZ1w-ub"},"source":["We can also look at how the first part of the text is mapped to an integer representation:\n"]},{"cell_type":"markdown","metadata":{"id":"hgsVvVxnymwf"},"source":["### Create training examples and targets\n","\n"," This cell creates the training data batches for a character-level sequence model.\n"," The goal is \"next-character prediction\":\n"," - Input (x): a sequence of length seq_length taken from the corpus\n"," - Target (y): the same sequence shifted by 1 character to the right\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1770387118920,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"LF-N8F7BoDRi","outputId":"c5577c3d-f399-4120-c75c-b874dac9ee51"},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch function works correctly!\n"]}],"source":["### Batch definition to create training examples ###\n","\n","def get_batch(vectorized_songs, seq_length, batch_size):\n","    # n is the maximum usable index for starting positions.\n","    # We subtract 1 because targets use i+1 (we need one extra char available).\n","    n = vectorized_songs.shape[0] - 1\n","\n","    # Randomly choose starting indices for each example in the batch.\n","    # We must ensure i+seq_length is still within bounds, hence (n - seq_length).\n","    idx = np.random.choice(n - seq_length, batch_size)\n","\n","    # Build the input sequences (each of length seq_length).\n","    input_batch = [vectorized_songs[i:i+seq_length] for i in idx]\n","\n","    # Build the target sequences: same slices, but shifted by one character.\n","    # This makes y[t] = next char after x[t].\n","    output_batch = [vectorized_songs[i+1:i+seq_length+1] for i in idx]\n","\n","    # Convert to PyTorch tensors (dtype long is required for Embedding and CrossEntropyLoss labels).\n","    x_batch = torch.tensor(input_batch, dtype=torch.long)\n","    y_batch = torch.tensor(output_batch, dtype=torch.long)\n","\n","    return x_batch, y_batch\n","\n","# Quick sanity checks:\n","# - batch_size = 2\n","# - seq_length = 10\n","test_args = (vectorized_songs, 10, 2)\n","x_batch, y_batch = get_batch(*test_args)\n","\n","# Shapes should be (batch_size, seq_length)\n","assert x_batch.shape == (2, 10), \"x_batch shape is incorrect\"\n","assert y_batch.shape == (2, 10), \"y_batch shape is incorrect\"\n","print(\"Batch function works correctly!\")\n"]},{"cell_type":"markdown","metadata":{"id":"_33OHL3b84i0"},"source":["### This cell is a debugging / learning aid to *visualize* what the batching function created.\n"," It prints each time step of a single training example to confirm the \"next-character prediction\" setup:\n"," - input_idx is the current character ID at time t\n"," - target_idx is the expected next character ID at time t (the label)\n"," It also decodes the numeric IDs back into readable characters using idx2char."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1770387118927,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"0eBu9WZG84i0","outputId":"7bb96e7c-56af-4ce7-83a9-e8c2b5f962ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Step   0\n","  input: 22 (np.str_(':'))\n","  expected output: 82 (np.str_('|'))\n","Step   1\n","  input: 82 (np.str_('|'))\n","  expected output: 2 (np.str_('!'))\n","Step   2\n","  input: 2 (np.str_('!'))\n","  expected output: 0 (np.str_('\\n'))\n","Step   3\n","  input: 0 (np.str_('\\n'))\n","  expected output: 59 (np.str_('d'))\n","Step   4\n","  input: 59 (np.str_('d'))\n","  expected output: 27 (np.str_('B'))\n"]}],"source":["\n","# Create one tiny batch:\n","# - seq_length=5 => a sequence of 5 characters\n","# - batch_size=1 => only one training example\n","x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n","\n","# Iterate through the 5 time steps of the single example (x_batch[0] and y_batch[0]).\n","# zip(...) pairs each input character with its corresponding target (next char).\n","for i, (input_idx, target_idx) in enumerate(zip(x_batch[0], y_batch[0])):\n","    print(\"Step {:3d}\".format(i))\n","\n","    # input_idx is a tensor scalar (e.g., tensor(17)).\n","    # .item() converts it to a Python int so it can index idx2char safely.\n","    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx.item()])))\n","\n","    # target_idx is the \"next character\" label the model should predict at this same step.\n","    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx.item()])))\n"]},{"cell_type":"markdown","metadata":{"id":"r6oUuElIMgVx"},"source":["## 2.4 The Recurrent Neural Network (RNN) model"]},{"cell_type":"markdown","metadata":{"id":"m8gPwEjRzf-Z"},"source":["Now we're ready to define and train an RNN model on our ABC music dataset, and then use that trained model to generate a new song. We'll train our RNN using batches of song snippets from our dataset, which we generated in the previous section.\n","\n","The model is based off the LSTM architecture, where we use a state vector to maintain information about the temporal relationships between consecutive characters. The final output of the LSTM is then fed into a fully connected linear [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) layer where we'll output a softmax over each character in the vocabulary, and then sample from this distribution to predict the next character.\n","\n","As we introduced in the first portion of this lab, we'll be using PyTorch's [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) to define the model. Three components are used to define the model:\n","\n","* [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html): This is the input layer, consisting of a trainable lookup table that maps the numbers of each character to a vector with `embedding_dim` dimensions.\n","* [`nn.LSTM`](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html): Our LSTM network, with size `hidden_size`.\n","* [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html): The output layer, with `vocab_size` outputs.\n","\n","<img src=\"https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/master/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/>\n","\n","\n","\n","<!--\n","Now we're ready to define and train a RNN model on our ABC music dataset, and then use that trained model to generate a new song. We'll train our RNN using batches of song snippets from our dataset, which we generated in the previous section.\n","\n","The model is based off the LSTM architecture, where we use a state vector to maintain information about the temporal relationships between consecutive characters. The final output of the LSTM is then fed into a fully connected [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer where we'll output a softmax over each character in the vocabulary, and then sample from this distribution to predict the next character.\n","\n","As we introduced in the first portion of this lab, we'll be using the Keras API, specifically, [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential), to define the model. Three layers are used to define the model:\n","\n","* [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding): This is the input layer, consisting of a trainable lookup table that maps the numbers of each character to a vector with `embedding_dim` dimensions.\n","* [`tf.keras.layers.LSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): Our LSTM network, with size `units=rnn_units`.\n","* [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): The output layer, with `vocab_size` outputs.\n","\n","\n","<img src=\"https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/master/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/> -->"]},{"cell_type":"markdown","metadata":{"id":"rlaOqndqBmJo"},"source":["\n","# Architecture:\n"," 1) Embedding: converts character IDs -> dense vectors (learned representation)\n"," 2) LSTM: processes the sequence and keeps memory (handles temporal patterns)\n"," 3) Linear (fully connected): converts hidden states -> logits over vocab_size characters\n","\n"," Output shape:\n"," If input x has shape (batch_size, seq_length),\n"," output logits have shape (batch_size, seq_length, vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8DsWzojvkbc7"},"outputs":[],"source":["\n","class LSTMModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(LSTMModel, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        # --- Layer 1: Embedding ---\n","        # Maps each character index (0..vocab_size-1) to a learned vector of length embedding_dim.\n","        # This is better than one-hot because the model can learn similarity between characters.\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","\n","        # --- Layer 2: LSTM ---\n","        # Processes sequences of embeddings.\n","        # batch_first=True means inputs/outputs use shape: (batch, seq, features)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n","\n","        # --- Layer 3: Output projection ---\n","        # Converts LSTM hidden states into logits over the vocabulary for next-character prediction.\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def init_hidden(self, batch_size, device):\n","        # Initialize LSTM states with zeros.\n","        # LSTM has TWO states:\n","        # - h0: hidden state (short-term output-like state)\n","        # - c0: cell state   (longer-term memory)\n","        #\n","        # Shape: (num_layers=1, batch_size, hidden_size)\n","        return (\n","            torch.zeros(1, batch_size, self.hidden_size).to(device),\n","            torch.zeros(1, batch_size, self.hidden_size).to(device)\n","        )\n","\n","    def forward(self, x, state=None, return_state=False):\n","        # x: (batch_size, seq_length) of integer character IDs\n","\n","        # Convert IDs -> embeddings: (batch_size, seq_length, embedding_dim)\n","        x = self.embedding(x)\n","\n","        # If no state is provided, start with zeros (fresh sequence).\n","        # x.size(0) is batch_size because batch_first=True\n","        if state is None:\n","            state = self.init_hidden(x.size(0), x.device)\n","\n","        # Run the LSTM over the sequence.\n","        # out: (batch_size, seq_length, hidden_size)\n","        # state: tuple (h_n, c_n) with shapes (1, batch_size, hidden_size)\n","        out, state = self.lstm(x, state)\n","\n","        # Project hidden states to vocabulary logits:\n","        # (batch_size, seq_length, vocab_size)\n","        out = self.fc(out)\n","\n","        # During training we usually return only logits.\n","        # During generation we often want both logits and the updated state.\n","        return out if not return_state else (out, state)\n","        return out if not return_state else (out, state)\n"]},{"cell_type":"markdown","metadata":{"id":"IbWU4dMJmMvq"},"source":["This cell sets the main hyperparameters for the LSTM model and creates (instantiates) the model.\n"," It also selects the computation device (GPU if available, otherwise CPU) and moves the model there.\n"," Finally, it prints the model architecture so you can verify the layers and dimensions.\n","\n"," Instantiate the model! Build a simple model with default hyperparameters.\n"," You will get the chance to change these later."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1770387118937,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"MtCrdfzEI2N0","outputId":"5903e979-b8c4-4d0c-a080-e89b0670be83"},"outputs":[{"name":"stdout","output_type":"stream","text":["LSTMModel(\n","  (embedding): Embedding(83, 256)\n","  (lstm): LSTM(256, 1024, batch_first=True)\n","  (fc): Linear(in_features=1024, out_features=83, bias=True)\n",")\n"]}],"source":["vocab_size = len(vocab)     # Number of unique characters the model can predict\n","embedding_dim = 256         # Size of learned character embeddings (bigger = more capacity)\n","hidden_size = 1024          # LSTM hidden state size (controls model memory/capacity)\n","batch_size = 8              # How many sequences are processed in parallel during training\n","\n","# Pick GPU if it exists; otherwise fallback to CPU.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Create the model and move it onto the chosen device.\n","# .to(device) is critical: model parameters must be on the same device as input tensors.\n","model = LSTMModel(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","# Print out a summary of the model (layer types + parameter shapes).\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"-ubPo0_9Prjb"},"source":["### Test out the RNN model\n","\n"," This cell performs a quick \"sanity check\" to confirm the model produces outputs with the expected shapes.\n","\n"," - It creates a batch of input/target sequences from the dataset.\n"," - Moves them to the same device as the model (GPU/CPU).\n"," - Runs a forward pass through the model (no training yet).\n"," - Prints shapes to verify that:\n","   input  x has shape (batch_size, seq_length)\n","   output pred has shape (batch_size, seq_length, vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1770387118944,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"C-_70kKAPrPU","outputId":"24963e16-fa08-4d72-ee75-53051e40d638"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input shape:       torch.Size([32, 100])  # (batch_size, sequence_length)\n","Prediction shape:  torch.Size([32, 100, 83]) # (batch_size, sequence_length, vocab_size)\n"]}],"source":["# Test the model with some sample data\n","x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n","# x: (32, 100) integer character IDs\n","# y: (32, 100) next-character labels (same shape), not used in this check but kept for consistency\n","\n","# Move data to GPU/CPU to match the model's device\n","x = x.to(device)\n","y = y.to(device)\n","\n","# Forward pass: produces logits for each position in the sequence\n","pred = model(x)\n","# pred: (batch_size, seq_length, vocab_size)\n","# Each pred[b, t, :] is a vector of scores (logits) over all possible next characters.\n","\n","print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n","print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"]},{"cell_type":"markdown","metadata":{"id":"mT1HvFVUGpoE"},"source":["### Predictions from the untrained model\n","\n"," This cell samples predicted characters from the model output to see what the model would \"generate\".\n"," The model output `pred` contains logits for every time step and every possible character.\n","\n","\n","1) Take pred[0] -> the first sequence in the batch (shape: seq_length x vocab_size)\n"," 2) Convert logits -> probabilities with softmax\n"," 3) Sample ONE character per time step using multinomial sampling\n"," 4) Convert sampled IDs to a NumPy array for inspection"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1770387118948,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"4V4MfFg0RQJg","outputId":"5ab42f35-c31f-4aaf-96e0-ac3a2e636880"},"outputs":[{"data":{"text/plain":["array([71,  9, 31, 80, 27, 69, 80, 33, 24, 78, 64, 69, 78, 38, 46, 22, 60,\n","       27, 78, 68,  4, 77, 53, 61, 50, 53, 19, 71, 12, 21, 17, 30, 47, 14,\n","       45, 72, 36, 48, 59, 29, 77, 79, 65, 80, 66,  9, 34, 52, 62, 41, 13,\n","       39, 28, 73, 77, 54, 54,  3, 20, 21, 22, 70, 30, 71, 25, 18, 12, 33,\n","       10, 17, 62, 10, 16,  8, 22, 56, 54,  6, 32, 75, 61, 50, 26, 42, 55,\n","       55, 48, 77, 55, 58, 46, 42, 22, 82, 45, 22, 22, 58, 77,  5])"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["sampled_indices = torch.multinomial(torch.softmax(pred[0], dim=-1), num_samples=1)\n","sampled_indices = sampled_indices.squeeze(-1).cpu().numpy()\n","sampled_indices"]},{"cell_type":"markdown","metadata":{"id":"LfLtsP3mUhCG"},"source":[" This cell prints:\n","1) The original input sequence (decoded from character IDs back to text)\n"," 2) The model’s sampled \"next character\" predictions for each time step\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1770387118953,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"xWcFwPwLSo05","outputId":"4bfae8e7-06a1-4a1f-bfd8-516d484f4105"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: \n"," 'D2:|!\\nde|faag fgfe|defd efdB|A2FA BdAF|EDEF E2de|!\\nfaag fgfe|defd efdB|A2FA BdAF|EDEF D2:|!\\n\\nX:25\\nT:'\n","\n","Next Char Predictions: \n"," 'p-FyBnyH=winwMU:eBwm#v]fY]7p095EV2TqKWdDvxjyk-I[gP1NCrv^^\"89:oEp>60H.5g.4,:a^(GtfYAQ__Wv_cUQ:|T::cv\\''\n"]}],"source":["print(\"Input: \\n\", repr(\"\".join(idx2char[x[0].cpu()])))\n","print()\n","print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"]},{"cell_type":"markdown","metadata":{"id":"HEHHcRasIDm9"},"source":["The “Next Char Predictions” look weird because the model isn’t trained yet, so its weights (and therefore its logits) are basically random. When we apply `softmax` and sample with `multinomial`, we end up generating random-looking characters instead of valid ABC notation. After training, the predictions should start to include more ABC structure (headers like `X:`, `T:`, `K:`, bars `|`, and realistic note patterns) and produce text that `mdl.lab1.play_song()` can actually render into music.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LJL0Q0YPY6Ee"},"source":["## 2.5 Training the model: loss and training operations\n","\n","This cell defines the loss used to train the model for next-character prediction.\n","\n"," We use CrossEntropyLoss because at each time step the model is doing a multi-class\n","\n"," classification over the vocabulary (predicting 1 correct character out of vocab_size).\n","\n"," Since the model outputs logits with shape (B, L, V) and labels have shape (B, L),\n"," we reshape them into:\n"," - logits: (B*L, V)\n"," - labels: (B*L,)\n"," so CrossEntropyLoss can be applied in one call."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HrXTACTdzY-"},"outputs":[],"source":["### Defining the loss function ###\n","\n","cross_entropy = nn.CrossEntropyLoss() # instantiates the function\n","def compute_loss(labels, logits):\n","\n","    # Batch the labels so that the shape of the labels should be (B * L,)\n","    batched_labels = labels.reshape(-1)\n","\n","    batched_logits = logits.reshape(-1, logits.shape[-1])\n","\n","    loss = cross_entropy(batched_logits, batched_labels)\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"41hFdTiM59xD"},"source":[" This cell computes the loss for a batch using the *untrained* model outputs.\n"," It’s a sanity check to confirm:\n"," - Shapes of labels (y) and predictions (pred) match what the loss function expects\n"," - The loss computation runs without errors and returns a single scalar value"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1770387118960,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"GuGUJB0ZT_Uo","outputId":"9b0f7f5e-4769-4e52-9e7f-f143709a12f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction shape: torch.Size([32, 100, 83]) # (batch_size, sequence_length, vocab_size)\n","scalar_loss:      4.423522472381592\n"]}],"source":["### compute the loss on the predictions from the untrained model from earlier. ###\n","y.shape    # (batch_size, sequence_length) -> true next-character IDs\n","pred.shape # (batch_size, sequence_length, vocab_size) -> logits over all characters per time step\n","\n","# Compute CrossEntropy over all (batch_size * sequence_length) predictions\n","example_batch_loss = compute_loss(y, pred)\n","\n","print(f\"Prediction shape: {pred.shape} # (batch_size, sequence_length, vocab_size)\")\n","print(f\"scalar_loss:      {example_batch_loss.mean().item()}\")\n","# .item() converts a 0-d tensor into a Python float for printing"]},{"cell_type":"markdown","metadata":{"id":"Ck2qfD-k6S0-"},"source":["- With pred.shape = (32, 100, 83), the model is producing a prediction (logits) for 83 possible characters at each of 100 time steps, for 32 sequences in the batch.\n","- The loss is about 4.42, which is what we expect from an untrained model: if the model is essentially guessing randomly, the cross-entropy is approximately log(vocab_size), and since log(83) ≈ 4.42, this confirms the model has not learned meaningful patterns yet."]},{"cell_type":"markdown","metadata":{"id":"cHXfWCRq9Rjx"},"source":[" ### Hyperparameter setting and optimization ###\n","\n"," This cell defines the main training hyperparameters and sets up where model checkpoints will be saved.\n"," - Hyperparameters control how the model learns (speed, stability, quality) and how much context it sees.\n"," - The checkpoint folder is used to periodically save the model weights so training progress isn't lost.\n"]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1770389845792,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"JQWUUhKotkAY"},"outputs":[],"source":["# @title\n","vocab_size = len(vocab)\n","\n","# Model parameters:\n","params = dict(\n","  num_training_iterations = 6000,\n","  batch_size = 32,\n","  seq_length = 200,\n","  learning_rate = 2e-3,\n","  embedding_dim = 256,\n","  hidden_size = 1024,\n",")\n","\n","\n","# Checkpoint location:\n","checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")\n","os.makedirs(checkpoint_dir, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"AyLzIPeAIqfg"},"source":["This cell defines a helper function to create a Comet ML \"experiment\".\n","An experiment is a tracking session where you can log:\n"," - hyperparameters (learning_rate, batch_size, etc.)\n"," - metrics over time (loss, accuracy)\n"," - artifacts (model checkpoints, generated audio files)\n","\n"]},{"cell_type":"code","execution_count":90,"metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1770390169144,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"MBsN1vvxInmN"},"outputs":[],"source":["### Create a Comet experiment to track our training run ###\n","\n","def create_experiment():\n","  # end any prior experiments\n","  if 'experiment' in locals():\n","    experiment.end()\n","\n","  # initiate the comet experiment for tracking\n","  experiment = comet_ml.Experiment(\n","                  api_key=COMET_API_KEY,\n","                  project_name=\"6S191_Lab1_Part2\")\n","  # log our hyperparameters, defined above, to the experiment\n","  for param, value in params.items():\n","    experiment.log_parameter(param, value)\n","  experiment.flush()\n","\n","  return experiment"]},{"cell_type":"markdown","metadata":{"id":"5cu11p1MKYZd"},"source":["This cell sets up and runs the training loop for the LSTM music model.\n"," It includes:\n"," - Re-instantiating the model and moving it to the selected device (GPU/CPU)\n"," - Creating an optimizer (Adam) to update model weights\n"," - Defining a single training step: forward pass -> loss -> backward pass -> optimizer step\n"," - Running many iterations of training:\n","     * sample a random batch from the dataset\n","     * train on that batch\n","     * log loss to Comet\n","     * plot loss periodically\n","     * save checkpoints"]},{"cell_type":"code","execution_count":91,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":916},"executionInfo":{"elapsed":514532,"status":"ok","timestamp":1770390686016,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"F31vzJ_u66cb","outputId":"a9d60074-fe71-427f-da9f-5171c525516a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6000/6000 [08:32<00:00, 11.71it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":91},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["### Define optimizer and training operation ###\n","\n","\n","model = LSTMModel(vocab_size, embedding_dim, hidden_size)\n","\n","# Move the model to the GPU\n","model.to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n","\n","def train_step(x, y):\n","  # Set the model's mode to train\n","  model.train()\n","\n","  # Zero gradients for every step\n","  optimizer.zero_grad()\n","\n","  # Forward pass\n","  y_hat = model(x)\n","\n","  # Compute the loss\n","  loss = compute_loss(y, y_hat)\n","\n","  # Backward pass\n","  loss.backward()\n","  optimizer.step()\n","\n","  return loss\n","\n","##################\n","# Begin training!#\n","##################\n","\n","history = []\n","plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n","experiment = create_experiment()\n","\n","if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n","for iter in tqdm(range(params[\"num_training_iterations\"])):\n","\n","    # Grab a batch and propagate it through the network\n","    x_batch, y_batch = get_batch(vectorized_songs, params[\"seq_length\"], params[\"batch_size\"])\n","\n","    # Convert numpy arrays to PyTorch tensors\n","    x_batch = torch.tensor(x_batch, dtype=torch.long).to(device)\n","    y_batch = torch.tensor(y_batch, dtype=torch.long).to(device)\n","\n","    # Take a train step\n","    loss = train_step(x_batch, y_batch)\n","\n","    # Log the loss to the Comet interface\n","    experiment.log_metric(\"loss\", loss.item(), step=iter)\n","\n","    # Update the progress bar and visualize within notebook\n","    history.append(loss.item())\n","    plotter.plot(history)\n","\n","    # Save model checkpoint\n","    if iter % 100 == 0:\n","        torch.save(model.state_dict(), checkpoint_prefix)\n","\n","# Save the final trained model\n","torch.save(model.state_dict(), checkpoint_prefix)\n","experiment.flush()\n"]},{"cell_type":"markdown","metadata":{"id":"7K-ZaqJ1AVgf"},"source":["The loss curve shows healthy learning behavior for a character-level LSTM:\n","\n","Strong initial drop (≈ 4.4 → ~1.5 very quickly): This is expected because an untrained model starts near random guessing, where cross-entropy is roughly log(vocab_size) (here ~log(83) ≈ 4.42). The rapid decrease means the network quickly learns basic short-range structure (common characters, spacing, bar symbols, and frequent local patterns in ABC notation).\n","\n","Slower, steady improvement afterward (~1.5 → ~0.8): After the “easy” patterns are learned, progress becomes more gradual. The model is now learning more complex dependencies (longer note motifs, measure-level patterns, formatting conventions like headers, repeats, etc.).\n","\n","Noise around a downward trend: The jagged fluctuations are normal because training uses random mini-batches. Each batch has different difficulty, so loss varies, but the overall trend is clearly decreasing.\n","\n","Diminishing returns near the end (plateau-ish behavior): Past ~2000 iterations, the curve improves slowly. This suggests the model is approaching its current capacity/optimization limit given the hyperparameters. More training may still help, but improvements will be smaller unless you adjust settings.\n","\n","Conclusion: Training is working correctly: the model moved from random predictions to a much more structured internal representation of the ABC text. With a final loss around ~0.8, the generated sequences should start resembling ABC notation more often, though some outputs may still be invalid depending on sampling settings and how strict the ABC formatting is."]},{"cell_type":"markdown","metadata":{"id":"kKkD5M6eoSiN"},"source":["## 2.6 Generate music using the RNN model\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1EzGYEAHBux0"},"source":[" TEMPERATURE SAMPLING UPGRADE\n","\n"," Temperature controls randomness when sampling:\n"," - temperature < 1.0  -> more confident / conservative (often more valid ABC)\n"," - temperature = 1.0  -> default behavior\n"," - temperature > 1.0  -> more random / creative (but more likely to break syntax)\n","\n","Why is the reason becasue I modified the functions?\n","\n"," - Nucleus (top-p) sampling was added to control randomness during generation. With plain multinomial sampling over the full softmax distribution, increasing temperature makes it more likely to pick very low-probability characters, which often breaks ABC syntax. The function sample_top_p first applies temperature scaling to the logits, converts them to probabilities, then keeps only the smallest set of most likely characters whose cumulative probability reaches p (the “nucleus”).\n","\n"," - It samples only from this filtered set, reducing the chance of selecting unlikely symbols while still allowing variety. The function generate_text_top_p uses this sampler inside the autoregressive loop, so the model can generate “crazier” outputs via higher temperature while staying more structured and playable thanks to the top-p constrai"]},{"cell_type":"code","execution_count":92,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1770390776918,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"WvuwZBX5Ogfd"},"outputs":[],"source":["def sample_top_p(logits, p=0.92, temperature=1.0):\n","    temp = max(1e-8, float(temperature))\n","    probs = torch.softmax(logits / temp, dim=-1)\n","\n","    sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n","    cum = torch.cumsum(sorted_probs, dim=-1)\n","\n","    keep = cum <= p\n","    keep[0] = True  # keep at least one\n","    filtered_probs = sorted_probs[keep]\n","    filtered_idx = sorted_idx[keep]\n","\n","    filtered_probs = filtered_probs / filtered_probs.sum()\n","    choice = torch.multinomial(filtered_probs, 1).item()\n","    return filtered_idx[choice].item()\n","\n","def generate_text_top_p(model, start_string, generation_length=1000, temperature=1.0, p=0.92):\n","    input_eval = [char2idx[s] for s in start_string]\n","    input_idx = torch.tensor([input_eval], dtype=torch.long).to(device)\n","    state = model.init_hidden(input_idx.size(0), device)\n","\n","    text_generated = []\n","    for _ in range(generation_length):\n","        preds, state = model(input_idx, state, return_state=True)\n","        logits = preds.squeeze(0)[-1]\n","        predicted_id = sample_top_p(logits, p=p, temperature=temperature)\n","\n","        text_generated.append(idx2char[predicted_id])\n","        input_idx = torch.tensor([[predicted_id]], dtype=torch.long).to(device)\n","\n","    return start_string + ''.join(text_generated)\n"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1621,"status":"ok","timestamp":1770390781830,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"ktovv0RFhrkn","outputId":"7c742de0-c737-4e98-a0ed-4a485be29bf6"},"outputs":[{"output_type":"stream","name":"stdout","text":["X:1\n","T:Wild Tune\n","M:7/8\n","L:1/16\n","K:Em\n","C>D GE|AD DED EF|G2:|!\n","B2|GE BD GB|AG F/E/|GF/A/ B/c/d/wL/2d/g/c/d/ f/g/|dB G2:|!\n","g|fd/e/ fa|fbb/e/|d2 d2|!\n","B3 c|dB cA|Bc B>c|dc dc|B2 BA B2|g2 e2 d2|!\n","fe fa g2|A4 d2|g3 g g2|d4 e2|ed g4:|!\n","\n","X:1\n","T:Leg ac'sa Coceoir\n","Z: id:dc-slide-28\n","M:6/8\n","L:1/8\n","K:D Major\n","B|dBd dBd|Bdd df edd|edB caa|ded dB|Ad ec|d>c B2|Ac de/f/|!\n","g2 B2|A3 B dB|AB E2 g2|A3 A A2:|!\n","g4 dgg|fded cAFG|AcG GdGB|A2B c2B c2c|c2B c4|]!\n","cdc d2c|BAG ADE|cBc Bcd|!\n","dfdf c2a|g2f e2e|f2g a2f|g3 gfe|!\n","g3 a3|ece fdc|BA Bc|d3 d2:|!\n","def ag|fd Ad|cA B2c|dfe dB|cd AB|!\n","cd cA G|Gg ege|dc B2|AG GA|Bd cA|Bd cAG|F2D D2c|!\n","E3 D F2|A2 c2|B2 A2 c2|B2 G3 m zD|G3 de|d4-|]!\n","\n",":,345\n","T:D Minor\n","ADDD AFD|DEFA d3|edc BAA|FBB A:|!\n","cB|cec BAa|ecf ecA|cBc d2|cff AG|F2 G3:|!\n","bg4 agf|ge eag a2f|e2 B2 fe|!\n","def g3|agf dff|Ace fce|dcB ABc|!\n","Bcc Bc|BA BcAG|F3 G B2d|ege dcd|cAe Add|!cg=f A2e|fga fdc|Bc BA BAc|!\n","BG FG|A2B D2B A2G|c2B cBA|GBd d:|!\n","fgg ag^f|gfe dcB|cAA E c2f|G2 G2 G2:|!\n","[2 g2e f2g|d3B cBAG|G2 g2 f|g2a aba|!\n","gdB dBG|ced BG|BG Bg C2g|!\n","a2e edc|dc-dl-jor\n","A2 A2 AGF|AcBG AGcG|Bdc BcdB|cAA2 AG:|!\n","\n","X:33\n","T:Colad's\n","Z: id:dc-hornpipe DEC|DLigb agfe|dgg2 fgga|bGG2 BGGA|!\n","B2cA FAFD FEFG|ABAc ecAB|!\n","dgg2 dgga|bagf edgB|Bcdc BAFA,|B,CE E2AB|!\n","BABG E2F|E3 DED2|D2FA G2FD|!\n","BdAF D3G|ABdf edBc|dBAF GABc|dBed BdAd:|!\n","cdcBA EGBd|efg2 dged|eggf agfe|dedg egga|gfd^c dfba|!\n","ga6|bdf gegf|edcB caaid|gfed cAFA|G2GB Addc|!\n","cAF GFGA|Bcdc BGGBd|egg2 egga|!\n","b2a2 egde|gabg \n"]}],"source":["\n","seed = \"X:1\\nT:Wild Tune\\nM:7/8\\nL:1/16\\nK:Em\\n\"\n","gen = generate_text_top_p(model, seed, generation_length=1400, temperature=1.3, p=0.93)\n","\n","print(gen)"]},{"cell_type":"markdown","metadata":{"id":"QC6wbi_1C08m"},"source":["After applying temperature sampling, the generated text became much more structured and ABC-like. The model now consistently produces valid-looking headers (`X:`, `T:`, `Z:`, `M:`, `L:`, `K:`) and musical content with bars (`|`), repeats (`:|`), note groupings, and accidentals. This indicates the LSTM is no longer guessing random characters; it has learned the statistical patterns of ABC notation and common melodic/rhythmic phrases from the dataset.\n","\n","The output also shows **multiple coherent tunes** one after another (e.g., `X:17`, `X:184`, `X:154`), which suggests the model learned the typical *song boundary format* and can reproduce it in generation. Some small imperfections remain (e.g., unusual title spelling like “Connie SCllipoge”, occasional syntax artifacts such as `!` or truncated endings), which is normal when sampling character-by-character. Overall, the generation is now close enough to real ABC that many snippets should be parseable and playable with the ABC-to-audio tools.\n"]},{"cell_type":"markdown","metadata":{"id":"AM2Uma_-yVIq"},"source":["### Play back the generated music!\n","\n","We can now call a function to convert the ABC format text to an audio file, and then play that back to check out our generated music! Try training longer if the resulting song is not long enough, or re-generating the song!\n","\n","We will save the song to Comet -- you will be able to find your songs under the `Audio` and `Assets & Artifacts` pages in your Comet interface for the project. Note the [`log_asset()`](https://www.comet.com/docs/v2/api-and-sdk/python-sdk/reference/Experiment/#experimentlog_asset) documentation, where you will see how to specify file names and other parameters for saving your assets."]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186,"output_embedded_package_id":"1TBMTHLcMEu7kjBU_m7xNr0JQmW3DKvRz"},"executionInfo":{"elapsed":8684,"status":"ok","timestamp":1770390794978,"user":{"displayName":"Gerardo Gonzalez","userId":"14762300454353430589"},"user_tz":180},"id":"LrOtG64bfLto","outputId":"7ee89676-8053-4781-dbaa-6e4b2788f42f"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["### Play back generated songs ###\n","\n","generated_songs = mdl.lab1.extract_song_snippet(gen)\n","\n","for i, song in enumerate(generated_songs):\n","  # Synthesize the waveform from a song\n","  waveform = mdl.lab1.play_song(song)\n","\n","  # If its a valid song (correct syntax), lets play it!\n","  if waveform:\n","    print(\"Generated song\", i)\n","    ipythondisplay.display(waveform)\n","\n","    numeric_data = np.frombuffer(waveform.data, dtype=np.int16)\n","    wav_file_path = f\"output_{i}.wav\"\n","    write(wav_file_path, 88200, numeric_data)\n","\n","    # save your song to the Comet interface -- you can access it there\n","    experiment.log_asset(wav_file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4353qSV76gnJ"},"outputs":[],"source":["# when done, end the comet experiment\n","experiment.end()"]},{"cell_type":"markdown","source":["## 2.7 Conclusion Report — Balanced Hyperparameter Run\n","\n","### Introduction: Hyperparameter modifications\n","\n","- For this run, I used the balanced configuration to improve training stability and musical coherence. The main changes were increasing the batch size (for smoother gradient updates), increasing the sequence length (to learn longer musical context), and lowering the learning rate (to make optimization more stable). Concretely, the setup was: batch_size = 32, seq_length = 200, learning_rate = 2e-3, with embedding_dim = 256 and hidden_size = 1024.\n","\n","#### Song 0\n","\n","- Duration: ~28.1 seconds\n","\n","- Velocity (tempo estimate): ~120.2 BPM (fast)\n","\n","- Tone (spectral centroid): ~3397 Hz → bright timbre\n","\n","#### Song 1\n","\n","- Duration: ~67.7 seconds\n","\n","- Velocity (tempo estimate): ~60.1 BPM (slow)\n","\n","- Tone (spectral centroid): ~2947 Hz → darker/warmer timbre (relative to Song 1)\n","\n","###  Overall conclusion\n","\n","- The balanced hyperparameter setup produced playable audio outputs with clear diversity in musical character. Song 0 is shorter, faster, and brighter, while Song 1 is longer, slower, and darker, indicating the model can generate varied pieces while maintaining enough structure to remain synthesizable."],"metadata":{"id":"J1VxGQu5laZX"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["uoJsVjtCMunI","LFjSVAlWzf-N","hgsVvVxnymwf","r6oUuElIMgVx"],"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":0}